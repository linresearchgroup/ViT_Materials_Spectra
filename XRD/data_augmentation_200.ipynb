{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loaded_df = pd.read_pickle(\"....pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from scipy.interpolate import interp1d, UnivariateSpline\n",
    "from scipy.special import gamma\n",
    "from scipy.special import voigt_profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-exclusive",
   "metadata": {},
   "source": [
    "# Old Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i1=5\n",
    "i2=14\n",
    "input_data_size = len(loaded_df)\n",
    "new_training_data = np.zeros((input_data_size * i1 * i2, 2251))\n",
    "label_lists = []\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(input_data_size):\n",
    "    #print(i)\n",
    "    label = loaded_df.iloc[i, 0]\n",
    "    print(label)\n",
    "    theoretical = loaded_df.iloc[i, 1:].values\n",
    "    len1 = len(theoretical)\n",
    "\n",
    "    lc_id1 = i * i1 * i2\n",
    "\n",
    "    for j in range(i1):\n",
    "        lc_id2 = j * i2\n",
    "\n",
    "        for k in range(i2):  # expand each data to 6*12=72 data\n",
    "            copy_theo = np.copy(theoretical)  # Create a copy of the original data to avoid modifying it directly\n",
    "\n",
    "            # Replace the peak-specific operations with the random elimination and scaling processes\n",
    "            # Random elimination\n",
    "            dum1 = np.repeat(np.random.choice([0, 1], 300, p=[0.2, 0.8]), len(copy_theo) // 300)\n",
    "            dum1 = np.append(dum1, np.zeros([len(copy_theo) - len(dum1), ]))\n",
    "            copy_theo = np.multiply(copy_theo, dum1)\n",
    "\n",
    "            # Random scaling\n",
    "            dum2 = np.repeat(np.random.rand(150,), len(copy_theo) // 150)\n",
    "            dum2 = np.append(dum2, np.zeros([len(copy_theo) - len(dum2), ]))\n",
    "            copy_theo = np.multiply(copy_theo, dum2)\n",
    "\n",
    "\n",
    "    \n",
    "            # Normalize the data\n",
    "            copy_theo_elimination_scaling=copy_theo\n",
    "            copy_theo_elimination_scaling = (copy_theo_elimination_scaling - np.min(copy_theo_elimination_scaling)) / (\n",
    "                np.max(copy_theo_elimination_scaling) - np.min(copy_theo_elimination_scaling) + 1e-9)\n",
    "\n",
    "            # Add noise\n",
    "            #noise_intensity = np.random.uniform(0, 0.005)\n",
    "            noise_intensity=0\n",
    "            noise = np.random.normal(0, noise_intensity * np.max(copy_theo_elimination_scaling), len(copy_theo_elimination_scaling))\n",
    "            copy_theo_elimination_scaling += noise\n",
    "\n",
    "            # Normalize again\n",
    "            copy_theo_elimination_scaling = (copy_theo_elimination_scaling - np.min(copy_theo_elimination_scaling)) / (\n",
    "                np.max(copy_theo_elimination_scaling) - np.min(copy_theo_elimination_scaling) + 1e-9)\n",
    "\n",
    "            # Left-right shifting process\n",
    "            shift = np.random.randint(-25 * 1, 25)  # Generate a random integer between -20 and 20 for left-right shifting\n",
    "            if shift >= 0:\n",
    "                # Shift data to the right\n",
    "                copy_theo_elimination_scaling = np.append(copy_theo_elimination_scaling[shift:], np.zeros([shift,]))\n",
    "            else:\n",
    "                # Shift data to the left\n",
    "                copy_theo_elimination_scaling = np.append(copy_theo_elimination_scaling[0:len1 + shift],\n",
    "                                                          np.zeros([shift * -1,]))\n",
    "\n",
    "\n",
    "            lc_id = lc_id1 + lc_id2 + k\n",
    "\n",
    "            new_training_data[lc_id] = copy_theo_elimination_scaling\n",
    "            label_lists.append(label)  # Move the label appending inside the loop\n",
    "\n",
    "new_train = new_training_data.tolist()\n",
    "\n",
    "# Create a new dataframe for the processed data\n",
    "new_train_df = pd.DataFrame(new_train)\n",
    "\n",
    "# Add labels as the first column\n",
    "new_train_df.insert(0, 'Label', label_lists)\n",
    "\n",
    "print('the total train data number is:  {}'.format(len(new_train)))\n",
    "print('the total train label number is:  {}'.format(len(label_lists)))\n",
    "\n",
    "# Save the new dataframe to a file\n",
    "#new_train_df.to_csv('augmented_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-knife",
   "metadata": {},
   "source": [
    "# Our Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-closing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i1=10\n",
    "i2=20\n",
    "input_data_size = len(loaded_df)\n",
    "new_training_data = np.zeros((input_data_size * i1 * i2, 2251))\n",
    "label_lists = []\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(input_data_size):\n",
    "    #print(i)\n",
    "    label = loaded_df.iloc[i, 0]\n",
    "    print(label)\n",
    "    theoretical = loaded_df.iloc[i, 1:].values\n",
    "    len1 = len(theoretical)\n",
    "\n",
    "    lc_id1 = i * i1 * i2\n",
    "\n",
    "    for j in range(i1):\n",
    "        lc_id2 = j * i2\n",
    "\n",
    "        for k in range(i2):  # expand each data to 6*12=72 data\n",
    "            copy_theo = np.copy(theoretical)  # Create a copy of the original data to avoid modifying it directly\n",
    "\n",
    "            # Replace the peak-specific operations with the random elimination and scaling processes\n",
    "            # Random elimination\n",
    "            dum1 = []\n",
    "            while len(dum1) < len(copy_theo):\n",
    "                repeat_count = np.random.randint(7, 9)  # Randomly choose a number between 7 and 8\n",
    "                dum1 = np.append(dum1, np.repeat(np.random.choice([0, 1], 1, p=[0.2, 0.8]), repeat_count))\n",
    "            dum1 = dum1[:len(copy_theo)]  # if dum1 is longer than copy_theo, truncate it\n",
    "            copy_theo = np.multiply(copy_theo, dum1)\n",
    "            \n",
    "            dum2 = []\n",
    "            while len(dum2) < len(copy_theo):\n",
    "                dum2 = np.repeat(np.random.rand(150,), len(copy_theo) // 150)\n",
    "                repeat_count = np.random.randint(14, 17)  # Randomly choose a number between 7 and 8\n",
    "                dum2 = np.append(dum2, np.repeat(np.random.rand(150,), repeat_count))\n",
    "            dum2 = dum2[:len(copy_theo)]  # if dum1 is longer than copy_theo, truncate it\n",
    "            copy_theo = np.multiply(copy_theo, dum2)            \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "            # Normalize the data\n",
    "            copy_theo_elimination_scaling=copy_theo\n",
    "            copy_theo_elimination_scaling = (copy_theo_elimination_scaling - np.min(copy_theo_elimination_scaling)) / (\n",
    "                np.max(copy_theo_elimination_scaling) - np.min(copy_theo_elimination_scaling) + 1e-9)\n",
    "\n",
    "            # Add noise\n",
    "            #noise_intensity = np.random.uniform(0, 0.005)\n",
    "            noise_intensity=0\n",
    "            noise = np.random.normal(0, noise_intensity * np.max(copy_theo_elimination_scaling), len(copy_theo_elimination_scaling))\n",
    "            copy_theo_elimination_scaling += noise\n",
    "\n",
    "            # Normalize again\n",
    "            copy_theo_elimination_scaling = (copy_theo_elimination_scaling - np.min(copy_theo_elimination_scaling)) / (\n",
    "                np.max(copy_theo_elimination_scaling) - np.min(copy_theo_elimination_scaling) + 1e-9)\n",
    "\n",
    "            # Left-right shifting process\n",
    "            shift = np.random.randint(-25 * 1, 25)  # Generate a random integer between -20 and 20 for left-right shifting\n",
    "            if shift >= 0:\n",
    "                # Shift data to the right\n",
    "                copy_theo_elimination_scaling = np.append(copy_theo_elimination_scaling[shift:], np.zeros([shift,]))\n",
    "            else:\n",
    "                # Shift data to the left\n",
    "                copy_theo_elimination_scaling = np.append(copy_theo_elimination_scaling[0:len1 + shift],\n",
    "                                                          np.zeros([shift * -1,]))\n",
    "\n",
    "\n",
    "            lc_id = lc_id1 + lc_id2 + k\n",
    "\n",
    "            new_training_data[lc_id] = copy_theo_elimination_scaling\n",
    "            label_lists.append(label)  # Move the label appending inside the loop\n",
    "\n",
    "#new_train = new_training_data.tolist()\n",
    "\n",
    "# Create a new dataframe for the processed data\n",
    "#new_train_df = pd.DataFrame(new_train)\n",
    "new_train_df = pd.DataFrame(new_training_data)\n",
    "\n",
    "# Add labels as the first column\n",
    "new_train_df.insert(0, 'Label', label_lists)\n",
    "\n",
    "print('the total train data number is:  {}'.format(len(new_train)))\n",
    "print('the total train label number is:  {}'.format(len(label_lists)))\n",
    "\n",
    "# Save the new dataframe to a file\n",
    "#new_train_df.to_csv('augmented_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_train_df.to_pickle(\"....pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37torch",
   "language": "python",
   "name": "py37torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
