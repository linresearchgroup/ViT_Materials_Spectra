{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.ConfigProto()\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "\n",
    "gpu_options=tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import keras\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from keras.layers import AveragePooling1D, MaxPooling1D, Bidirectional, GlobalMaxPool1D, Concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D,concatenate\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from math import floor\n",
    "import warnings\n",
    "from keras import backend as K\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Number of available GPUs:\", len(gpus))\n",
    "    for i in range(len(gpus)):\n",
    "        print(\"GPU name:\", gpus[i].name)\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('....pkl', 'rb') as f:\n",
    "    Data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iput_class = 2000\n",
    "oput_class = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_time=200\n",
    "numtrain = iput_class * aug_time\n",
    "numval = int(0.2 * iput_class)\n",
    "# Extract features and labels\n",
    "X = Data.iloc[:, 1:].values\n",
    "y = Data.iloc[:, 0].values\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split your data into training and validation sets:\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_csv(log_file,early_stopping_setting, epoch, elapsed_time, top1, top3, top5):\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(log_file):\n",
    "        # Open file in write mode and write headers\n",
    "        with open(log_file, mode='w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"early_stopping_setting\",\"Epoch\", \"Elapsed_Time\", \"Top1\", \"Top3\", \"Top5\"])\n",
    "            \n",
    "    # File exists, open in append mode and write data\n",
    "    with open(log_file, mode='a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([early_stopping_setting,epoch, elapsed_time, top1, top3, top5])\n",
    "class CustomEarlyStopping(Callback):\n",
    "    def __init__(self, patience=0, early_step_setting=0.95):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.early_step_setting = early_step_setting\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_loss = logs.get('loss')\n",
    "        self.losses.append(current_loss)\n",
    "\n",
    "        if epoch > 5 and current_loss > self.losses[epoch - 1] * self.early_step_setting:\n",
    "            self.wait += 1\n",
    "            print('\\n',self.wait)\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Early stopping!\")\n",
    "def calculate_top_k_accuracy(y_true, y_pred, k):\n",
    "    top_k_preds = np.argsort(y_pred, axis=-1)[:, -k:]\n",
    "    target_in_top_k = [(true in top_k) for true, top_k in zip(y_true, top_k_preds)]\n",
    "    return np.mean(target_in_top_k)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "for iiiii in range(100):\n",
    "    keras.backend.clear_session()\n",
    "    # Construct CNN layers\n",
    "    # more para-LeNet-5\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(6, 5, strides = 1, activation = 'relu', input_shape = (2251, 1)))\n",
    "    cnn_model.add(MaxPooling1D(2, strides = 2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Conv1D(16, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(Conv1D(16, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(2, strides = 2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Conv1D(32, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(Conv1D(32, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(2, strides = 2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Conv1D(64, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(Conv1D(64, 5, strides = 1, activation = 'relu'))\n",
    "    cnn_model.add(MaxPooling1D(2, strides = 2))\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(120, activation = 'relu'))\n",
    "    cnn_model.add(Dense(84, activation = 'relu'))\n",
    "    cnn_model.add(Dense(oput_class, activation = 'softmax', activity_regularizer = keras.regularizers.l2(0.1)))\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    #cnn_model.summary()\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_onehot = to_categorical(y_train)\n",
    "    y_val_onehot = to_categorical(y_val)\n",
    "\n",
    "    # Set up early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "    early_stopping_setting=1\n",
    "    custom_early_stopping = CustomEarlyStopping(patience=3, early_step_setting=early_stopping_setting)\n",
    "    start_time = time.time()\n",
    "    cnn_model.fit(\n",
    "        #X_train.numpy().reshape(X_train.shape[0], X_train.shape[1], 1), \n",
    "        X_train.reshape(X_train.shape[0], X_train.shape[1], 1), \n",
    "\n",
    "        y_train_onehot, \n",
    "        batch_size = 700, \n",
    "        epochs = 30, \n",
    "        verbose = 1,\n",
    "        validation_data=(X_val.reshape(X_val.shape[0], X_val.shape[1], 1), y_val_onehot),\n",
    "        callbacks=[custom_early_stopping]\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = cnn_model.predict(X_val.reshape(X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "    # Calculate top-1, top-3, top-5 accuracies\n",
    "    top_1_accuracy = calculate_top_k_accuracy(y_val, y_pred, 1)\n",
    "    top_3_accuracy = calculate_top_k_accuracy(y_val, y_pred, 3)\n",
    "    top_5_accuracy = calculate_top_k_accuracy(y_val, y_pred, 5)\n",
    "\n",
    "    print(f\"Top-1 Accuracy: {round(top_1_accuracy, 2) * 100}%\")\n",
    "    print(f\"Top-3 Accuracy: {round(top_3_accuracy, 2) * 100}%\")\n",
    "    print(f\"Top-5 Accuracy: {round(top_5_accuracy, 2) * 100}%\")\n",
    "\n",
    "    # Plot training loss\n",
    "    #plt.plot(custom_early_stopping.losses)\n",
    "    #plt.title('Model loss')\n",
    "    #plt.ylabel('Loss')\n",
    "    #plt.xlabel('Epoch')\n",
    "    #plt.legend(['Train'], loc='upper right')\n",
    "    #plt.show()\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Fit the scaler on the training data\n",
    "    #scaler = StandardScaler()\n",
    "\n",
    "    Test = pd.read_csv('....csv')\n",
    "\n",
    "    X_test = Test.iloc[:,1:]\n",
    "    y_true = Test.iloc[:,0]\n",
    "\n",
    "    per_sample_results = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test.iloc[i].values.reshape(1, 2251, 1)\n",
    "        y_true_sample = y_true[i]\n",
    "\n",
    "        y_pred_sample = cnn_model.predict(x)\n",
    "        \n",
    "        # Get the top k predictions\n",
    "        top_1_preds = np.argsort(y_pred_sample, axis=-1)[:, -1:]\n",
    "        top_3_preds = np.argsort(y_pred_sample, axis=-1)[:, -3:]\n",
    "        top_5_preds = np.argsort(y_pred_sample, axis=-1)[:, -5:]\n",
    "\n",
    "        true_label_encoded = label_encoder.transform([y_true_sample])\n",
    "\n",
    "        # Initialize counters\n",
    "        correct_top1 = correct_top3 = correct_top5 = 0\n",
    "\n",
    "        if true_label_encoded in top_1_preds[0]:\n",
    "            correct_top1 = 1\n",
    "\n",
    "        if true_label_encoded in top_3_preds[0]:\n",
    "            correct_top3 = 1\n",
    "\n",
    "        if true_label_encoded in top_5_preds[0]:\n",
    "            correct_top5 = 1\n",
    "\n",
    "        per_sample_results.extend([correct_top1, correct_top3, correct_top5])\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    '''...'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
